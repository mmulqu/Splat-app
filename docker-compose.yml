version: '3.8'

services:
  splat-local:
    build:
      context: ./local-server
      dockerfile: Dockerfile
    image: splat-local-nerfstudio:latest
    container_name: gaussian-splatting-local
    ports:
      - "5000:5000"    # Flask API
      - "7007:7007"    # Nerfstudio viewer
    volumes:
      # Mount application files
      - ./local-server/app.py:/app/app.py:ro
      - ./local-server/index.html:/app/index.html:ro
      - ./local-server/nerfstudio_handler.py:/app/handler.py:ro
      # Mount volumes for persistent storage
      - ./local-data/uploads:/workspace/uploads
      - ./local-data/outputs:/workspace/outputs
      # Cache directory to avoid re-downloading models
      - ./local-data/cache:/home/user/.cache/
      # Optional: Mount your own images directory
      # - ./my-images:/workspace/my-images:ro
    working_dir: /app
    command: python3 /app/app.py
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    shm_size: '12gb'
    restart: unless-stopped
    stdin_open: true
    tty: true

  # Optional: GPU monitoring with nvidia-smi
  gpu-monitor:
    image: nvidia/cuda:11.8.0-base-ubuntu22.04
    container_name: gpu-monitor
    command: watch -n 1 nvidia-smi
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    profiles:
      - monitoring
